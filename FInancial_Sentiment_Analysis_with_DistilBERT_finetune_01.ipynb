{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N9Nhq4gpEwG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "import spacy\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import precision_recall_fscore_support, cohen_kappa_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4-zGHnle2U3",
        "outputId": "d71fed80-e1eb-47e4-e0d0-9b9f0f712911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.56.1\n"
          ]
        }
      ],
      "source": [
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "6dc2091d11bc4f98ae381bf1fa66ed55",
            "1d51d02d268f4c359463775a3aa4ad86",
            "e97a87925f104b589b8637cfbff34e33",
            "4a9630d5b770491d90e7e7927ddc3837",
            "7a51b88ec28847f5a7f98596e58b1124",
            "772ee1dea4bb49ac80ff1be642be1ae8",
            "8dbf6feb45944eaea4fb621143e68957",
            "9b8323ae1b084025942f8b160288b6b1",
            "3034be458cde4c809935f90aa345cbd0",
            "d3a0c4cb4f244bf3a8a2f7bc5932c746",
            "d3793d194fe54cd3aa8c5ea325681e92",
            "5b25cb8223864d30a5c76b28fc91f8b0",
            "4f9a0d7c61b245a28db12ac9e3bdeb6b",
            "1cc31e11a918488d880df3315de46c51",
            "eea2aedbc450401a88c99882244111f3",
            "4502fe8c0724450680c8ab953d259f70",
            "8affddb147484f36ba623d56e15d92d3",
            "77c89a64a762482584f598bd89e2e806",
            "ec0f18a60f3d4ad5b0cabf8f1d45b860",
            "c291ac7811614130b6e24325b5105fb3"
          ]
        },
        "id": "XYcfOAMamnQg",
        "outputId": "1f8efdc4-28c0-4f21-9995-2e5dab166d04"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dc2091d11bc4f98ae381bf1fa66ed55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXY_tuzzgqsx"
      },
      "outputs": [],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXVqAIGTpJeJ"
      },
      "outputs": [],
      "source": [
        "# Download NLTK data\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    logger.error(\"SpaCy model 'en_core_web_sm' not found. Install it with: python -m spacy download en_core_web_sm\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmfpRXZqpMcm",
        "outputId": "46ab7dd1-f48b-4f02-b28c-6b209c04552c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT_vQ3wWpQUh",
        "outputId": "04f35b6a-ad74-4c4f-df12-d17f1b8a97c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using batch size: 8\n"
          ]
        }
      ],
      "source": [
        "# Set a batch size for processing - Reduced batch size\n",
        "batch_size = 8  # You can adjust this value based on your GPU memory\n",
        "print(f\"Using batch size: {batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUuwBaVkpWar"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "def create_ticker_map_csv(output_path=\"/content/company_tickers.csv\"):\n",
        "    sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
        "    tickers = sp500['Symbol'].tolist()\n",
        "    data = []\n",
        "    for ticker in tickers:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        info = stock.info\n",
        "        company_name = info.get(\"longName\", ticker)\n",
        "        canonical_name = info.get(\"shortName\", company_name.split()[0])\n",
        "        data.append({\"Company_Name\": company_name, \"Ticker\": ticker, \"Canonical_Name\": canonical_name})\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(output_path, index=False)\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4erPjdLopZmL"
      },
      "outputs": [],
      "source": [
        "# Function to load entity map from CSV\n",
        "def load_entity_map(csv_path=\"/content/company_tickers.csv\"):\n",
        "    \"\"\"Load company-ticker mappings from a CSV file.\"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    entity_map = {}\n",
        "    for _, row in df.iterrows():\n",
        "        # Store both Company Name and Ticker mapping to Canonical Name\n",
        "        entity_map[str(row['Company_Name'])] = str(row['Canonical_Name'])\n",
        "        entity_map[str(row['Ticker'])] = str(row['Canonical_Name'])\n",
        "    return entity_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX6-FWb0peG5"
      },
      "outputs": [],
      "source": [
        "# Step 1: Preprocessing with SpaCy NER\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and preprocess financial text using SpaCy NER.\"\"\"\n",
        "    try:\n",
        "        text = text[:10000]  # Limit to 10,000 characters\n",
        "        soup = BeautifulSoup(text, 'html.parser')\n",
        "        cleaned_text = soup.get_text()\n",
        "        cleaned_text = re.sub(r'[^\\w\\s\\$\\%\\.\\,]', '', cleaned_text)\n",
        "        sentences = nltk.sent_tokenize(cleaned_text)\n",
        "        normalized_sentences = []\n",
        "        for sentence in sentences:\n",
        "            if len(sentence) > 1000:\n",
        "                continue\n",
        "            normalized_sentence = sentence\n",
        "            for ticker, canonical in load_entity_map(csv_path=\"/content/company_tickers.csv\").items():\n",
        "                pattern = r'\\b' + re.escape(ticker) + r'\\b'\n",
        "                normalized_sentence = re.sub(pattern, canonical, normalized_sentence, flags=re.IGNORECASE)\n",
        "            doc = nlp(normalized_sentence)\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ == \"ORG\":\n",
        "                    canonical_name = ent.text.split()[0]\n",
        "                    normalized_sentence = normalized_sentence.replace(ent.text, canonical_name)\n",
        "            normalized_sentences.append(normalized_sentence)\n",
        "        return normalized_sentences if normalized_sentences else [text[:512]]\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error preprocessing text: {e}\")\n",
        "        return [text[:512]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed_xzOKkpfNY"
      },
      "outputs": [],
      "source": [
        "# Step 2: Named Entity Recognition\n",
        "def extract_entities(sentences):\n",
        "    \"\"\"Extract entities using FinBERT.\"\"\"\n",
        "    try:\n",
        "        ner_pipeline = pipeline(\n",
        "            \"ner\",\n",
        "            model=\"ProsusAI/finbert\",\n",
        "            tokenizer=\"ProsusAI/finbert\",\n",
        "            aggregation_strategy=\"simple\",\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            device=0 if torch.cuda.is_available() else -1\n",
        "        )\n",
        "        entities = []\n",
        "        for sentence in sentences:\n",
        "            ner_results = ner_pipeline(sentence)\n",
        "            sentence_entities = [{\"text\": entity[\"word\"], \"entity\": entity[\"entity_group\"], \"score\": entity[\"score\"]} for entity in ner_results]\n",
        "            entities.append({\"sentence\": sentence, \"entities\": sentence_entities})\n",
        "        return entities\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in NER: {e}\")\n",
        "        return [{\"sentence\": s, \"entities\": []} for s in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT5D9VH5piDX"
      },
      "outputs": [],
      "source": [
        "# Step 3: Relevance Classification using FinBERT\n",
        "def classify_relevance(sentences):\n",
        "  \"\"\"Classify sentences as financially relevant.\"\"\"\n",
        "  try:\n",
        "        classifier = pipeline(\"text-classification\",\n",
        "            model=\"ProsusAI/finbert\",\n",
        "            tokenizer=\"ProsusAI/finbert\",\n",
        "            max_length=512,\n",
        "            truncation=True\n",
        "        )\n",
        "        relevance_results = []\n",
        "        for sentence in sentences:\n",
        "            result = classifier(sentence)\n",
        "            is_relevant = result[0][\"label\"] == \"positive\" and result[0][\"score\"] > 0.7\n",
        "            relevance_results.append({\"sentence\": sentence, \"is_relevant\": is_relevant, \"score\": result[0][\"score\"]})\n",
        "        return relevance_results\n",
        "  except Exception as e:\n",
        "        logger.error(f\"Error in relevance classification: {e}\")\n",
        "        return [{\"sentence\": s, \"is_relevant\": False, \"score\": 0.0} for s in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiAmFoYNpkwb"
      },
      "outputs": [],
      "source": [
        "# Step 4: Sentiment Analysis\n",
        "def analyze_sentiment(sentences, model_id=\"ProsusAI/finbert\"):\n",
        "    \"\"\"Classify sentiment using a BERT-based model.\"\"\"\n",
        "    try:\n",
        "        sentiment_pipeline = pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=model_id,\n",
        "            tokenizer=model_id,\n",
        "            max_length=512,\n",
        "            truncation=True\n",
        "        )\n",
        "        sentiment_results = []\n",
        "        for sentence in sentences:\n",
        "            result = sentiment_pipeline(sentence)\n",
        "            # Map FinBERT's three-class output to binary (positive vs. negative)\n",
        "            label = result[0][\"label\"].lower()\n",
        "            binary_label = \"positive\" if label == \"positive\" else \"negative\"  # Neutral maps to negative\n",
        "            sentiment_results.append({\n",
        "                \"sentence\": sentence,\n",
        "                \"sentiment\": binary_label,\n",
        "                \"score\": result[0][\"score\"]\n",
        "            })\n",
        "        return sentiment_results\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in sentiment analysis with {model_id}: {e}\")\n",
        "        return [{\"sentence\": s, \"sentiment\": \"negative\", \"score\": 0.0} for s in sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSQ8SXGCSMcj"
      },
      "outputs": [],
      "source": [
        "# Step 5: Load Combined_News_DJIA.csv\n",
        "from datasets import ClassLabel\n",
        "\n",
        "def load_djia_dataset(file_path='/content/Combined_News_DJIA.csv', max_rows=None):\n",
        "    \"\"\"Load Combined_News_DJIA dataset from URL or local file.\"\"\"\n",
        "    try:\n",
        "        if file_path:\n",
        "            df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)\n",
        "        else:\n",
        "            url = \"https://raw.githubusercontent.com/niharikabalachandra/Stock-Market-Prediction-Using-Natural-Language-Processing/master/Combined_News_DJIA.csv\"\n",
        "            df = pd.read_csv(url, encoding='utf-8', low_memory=False)\n",
        "\n",
        "        logger.info(f\"CSV loaded: {df.shape}, Columns: {df.columns.tolist()}\")\n",
        "\n",
        "        df['text'] = df[['Top' + str(i) for i in range(1, 26)]].apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
        "        df = df.dropna(subset=['text', 'Label'])\n",
        "        df['text'] = df['text'].astype(str)\n",
        "\n",
        "        if max_rows is not None:\n",
        "            df = df.sample(n=min(max_rows, len(df)), random_state=42)\n",
        "            logger.info(f\"Subsampled to {len(df)} rows\")\n",
        "\n",
        "        df['label'] = df['Label'].astype(int)  # 0 = negative, 1 = positive\n",
        "\n",
        "        dataset = Dataset.from_pandas(df[['text', 'label']])\n",
        "\n",
        "        # Cast 'label' column to ClassLabel for stratification\n",
        "        dataset = dataset.cast_column('label', ClassLabel(names=[0, 1]))\n",
        "\n",
        "        if len(dataset) < 2:\n",
        "            raise ValueError(\"Dataset is too small for train-test split\")\n",
        "\n",
        "        try:\n",
        "            dataset = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='label')\n",
        "        except ValueError as e:\n",
        "            logger.warning(f\"Stratified split failed: {e}. Using non-stratified split.\")\n",
        "            dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "        logger.info(f\"Dataset prepared: {len(dataset['train'])} train, {len(dataset['test'])} test\")\n",
        "        return dataset\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading DJIA CSV: {e}\")\n",
        "        sample_data = {\n",
        "            \"text\": [\"Apple reported strong earnings.\", \"Sales declined sharply.\"],\n",
        "            \"label\": [1, 0]\n",
        "        }\n",
        "        df_sample = pd.DataFrame(sample_data)\n",
        "        dataset = Dataset.from_pandas(df_sample)\n",
        "        # Cast 'label' in sample data as well\n",
        "        dataset = dataset.cast_column('label', ClassLabel(names=[0, 1]))\n",
        "        dataset = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='label')\n",
        "        logger.info(\"Using sample data as fallback.\")\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snM8wXpPPbW2"
      },
      "outputs": [],
      "source": [
        "# Step 6: Fine-Tune FinBERT with LoRA\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def fine_tune_finbert_peft(file_path=\"./Combined_News_DJIA.csv\", output_dir=\"./finbert-finetuned-djia-lora\", max_rows=None):\n",
        "    \"\"\"Fine-tune FinBERT on Combined_News_DJIA dataset using LoRA.\"\"\"\n",
        "    try:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        logger.info(f\"Using device: {device}\")\n",
        "\n",
        "        dataset = load_djia_dataset(file_path, max_rows)\n",
        "        if dataset is None or len(dataset[\"train\"]) == 0:\n",
        "            raise ValueError(\"Failed to load dataset\")\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\", local_files_only=False)\n",
        "        # Load the base model with 3 labels to match pre-trained weights\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\", num_labels=3, local_files_only=False)\n",
        "\n",
        "        # Redefine the classifier head for 2 labels\n",
        "        num_labels = 2\n",
        "        model.classifier = torch.nn.Linear(model.classifier.in_features, num_labels)\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        lora_config = LoraConfig(\n",
        "            r=8,\n",
        "            lora_alpha=16,\n",
        "            target_modules=[\"query\", \"value\"], # Use \"query\", \"value\" for newer transformer versions\n",
        "            lora_dropout=0.1,\n",
        "            bias=\"none\",\n",
        "            task_type=\"SEQ_CLS\"\n",
        "        )\n",
        "        model = get_peft_model(model, lora_config)\n",
        "        model.print_trainable_parameters()\n",
        "        logger.info(\"LoRA model initialized\")\n",
        "\n",
        "        def tokenize_function(examples):\n",
        "            return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "        tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "        tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
        "        tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "\n",
        "        labels = np.array(tokenized_dataset[\"train\"][\"labels\"])\n",
        "        unique_labels = np.unique(labels)\n",
        "        expected_labels = np.array([0, 1]) # Expecting labels 0 and 1 after ClassLabel casting\n",
        "\n",
        "        class_weights = compute_class_weight(\"balanced\", classes=np.array([0, 1]), y=labels) # Compute weights for expected labels 0 and 1\n",
        "\n",
        "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "        logger.info(f\"Class weights: {class_weights}\")\n",
        "\n",
        "        class WeightedTrainer(Trainer):\n",
        "            def compute_loss(self, model, inputs, return_outputs=False):\n",
        "                labels = inputs.get(\"labels\").to(device)\n",
        "                outputs = model(**{k: v.to(device) for k, v in inputs.items()})\n",
        "                logits = outputs.get(\"logits\")\n",
        "                loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "                loss = loss_fct(logits, labels)\n",
        "                return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=16,\n",
        "            num_train_epochs=3,\n",
        "            learning_rate=2e-4,\n",
        "            weight_decay=0.01,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"f1\",\n",
        "            greater_is_better=True,\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            logging_dir=\"./logs\",\n",
        "            logging_steps=10,\n",
        "            report_to=\"none\" # Disable reporting to external services\n",
        "        )\n",
        "\n",
        "        def compute_metrics(eval_pred):\n",
        "            logits, labels = eval_pred\n",
        "            predictions = np.argmax(logits, axis=-1)\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
        "            kappa = cohen_kappa_score(labels, predictions)\n",
        "            return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"kappa\": kappa}\n",
        "\n",
        "        trainer = WeightedTrainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=tokenized_dataset[\"train\"],\n",
        "            eval_dataset=tokenized_dataset[\"test\"],\n",
        "            compute_metrics=compute_metrics,\n",
        "        )\n",
        "\n",
        "        logger.info(\"Starting fine-tuning with LoRA...\")\n",
        "        trainer.train()\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        model.save_pretrained(output_dir)\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "        logger.info(f\"LoRA-adapted model saved to {output_dir}\")\n",
        "        return output_dir\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in fine-tuning: {e}\")\n",
        "        return \"ProsusAI/finbert\" # Return base model path on error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgS0L84VS27l"
      },
      "outputs": [],
      "source": [
        "# Step 7: Summarization\n",
        "def summarize_text(text):\n",
        "    \"\"\"Generate summary using T5, handling short inputs.\"\"\"\n",
        "    try:\n",
        "        if len(text.strip()) < 10:  # Skip very short texts\n",
        "            logger.warning(f\"Text too short for summarization: {text[:50]}...\")\n",
        "            return text[:50]\n",
        "\n",
        "        summarizer = pipeline(\n",
        "            \"summarization\",\n",
        "            model=\"t5-base\",\n",
        "            tokenizer=\"t5-base\",\n",
        "            max_length=512,  # Input max_length\n",
        "            truncation=True,\n",
        "            device=0 if torch.cuda.is_available() else -1\n",
        "        )\n",
        "        input_length = len(text.split())\n",
        "        output_max_length = max(10, min(50, input_length // 2))  # Dynamic output length\n",
        "        summary = summarizer(text[:512], max_length=output_max_length, min_length=5, do_sample=False)\n",
        "        return summary[0][\"summary_text\"]\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in summarization: {e}\")\n",
        "        return text[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0B_nZINTCEH"
      },
      "outputs": [],
      "source": [
        "# Step 8: Aggregate Sentiment\n",
        "def aggregate_sentiment(sentiment_results):\n",
        "    \"\"\"Aggregate sentiment scores.\"\"\"\n",
        "    try:\n",
        "        sentiments = [r[\"sentiment\"] for r in sentiment_results]\n",
        "        scores = [r[\"score\"] for r in sentiment_results]\n",
        "        sentiment_counts = pd.Series(sentiments).value_counts()\n",
        "        majority_sentiment = sentiment_counts.idxmax() if not sentiment_counts.empty else \"negative\"\n",
        "        weighted_score = sum(scores) / len(scores) if scores else 0\n",
        "        return {\"majority_sentiment\": majority_sentiment, \"confidence\": weighted_score}\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error aggregating sentiment: {e}\")\n",
        "        return {\"majority_sentiment\": \"negative\", \"confidence\": 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URlUYn4VTJEo"
      },
      "outputs": [],
      "source": [
        "# Step 9: Evaluation Metrics\n",
        "def evaluate_model(true_labels, predicted_labels):\n",
        "    \"\"\"Compute evaluation metrics.\"\"\"\n",
        "    try:\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average=\"weighted\")\n",
        "        kappa = cohen_kappa_score(true_labels, predicted_labels)\n",
        "        return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"kappa\": kappa}\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error evaluating model: {e}\")\n",
        "        return {\"precision\": 0, \"recall\": 0, \"f1\": 0, \"kappa\": 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffbCCSb3Z3f1"
      },
      "outputs": [],
      "source": [
        "# Step 10: Predict Sentiments with Fine-Tuned LoRA Model\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "from peft import PeftModel\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def predict_sentiment_djia(\n",
        "    file_path=\"./Combined_News_DJIA.csv\",\n",
        "    model_path=\"./finbert-finetuned-djia-lora\",\n",
        "    output_path=\"DJIA_Predicted_Sentiments.csv\",\n",
        "    batch_size=16,\n",
        "    max_rows=None\n",
        "):\n",
        "    \"\"\"Predict sentiment for Combined_News_DJIA dataset using the fine-tuned LoRA model.\"\"\"\n",
        "    try:\n",
        "        if file_path:\n",
        "            df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)\n",
        "        else:\n",
        "            url = \"https://raw.githubusercontent.com/niharikabalachandra/Stock-Market-Prediction-Using-Natural-Language-Processing/master/Combined_News_DJIA.csv\"\n",
        "            df = pd.read_csv(url, encoding='utf-8', low_memory=False)\n",
        "\n",
        "        df['text'] = df[['Top' + str(i) for i in range(1, 26)]].apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
        "        df = df.dropna(subset=['text'])\n",
        "        df['text'] = df['text'].astype(str)\n",
        "\n",
        "        if max_rows is not None:\n",
        "            df = df.sample(n=min(max_rows, len(df)), random_state=42)\n",
        "            logger.info(f\"Subsampled to {len(df)} rows\")\n",
        "\n",
        "        # Load the base model with 3 labels and then the PEFT adapter\n",
        "        base_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\", num_labels=3)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "\n",
        "        # Load the LoRA adapter and merge using the model_path\n",
        "        model = PeftModel.from_pretrained(base_model, model_path)\n",
        "        model = model.merge_and_unload()\n",
        "\n",
        "        # Ensure the merged model has the correct classifier head for 2 labels\n",
        "        if model.classifier.out_features != 2:\n",
        "             logger.warning(f\"Model classifier has {model.classifier.out_features} output features, expected 2. Redefining.\")\n",
        "             model.classifier = torch.nn.Linear(model.classifier.in_features, 2)\n",
        "\n",
        "\n",
        "        device = 0 if torch.cuda.is_available() else -1\n",
        "        sentiment_pipeline = pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            device=device\n",
        "        )\n",
        "        logger.info(f\"Loaded LoRA-adapted model from {model_path}\")\n",
        "\n",
        "        predictions = []\n",
        "        scores = []\n",
        "        # Adjust label map for 2 output classes (0: negative, 1: positive)\n",
        "        label_map = {\n",
        "            \"LABEL_0\": \"negative\",\n",
        "            \"LABEL_1\": \"positive\",\n",
        "            \"negative\": \"negative\",\n",
        "            \"positive\": \"positive\"\n",
        "        }\n",
        "\n",
        "\n",
        "        texts = df['text'].tolist()\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting sentiments\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            batch_texts = [text[:512] for text in batch_texts]\n",
        "            results = sentiment_pipeline(batch_texts)\n",
        "\n",
        "            for result in results:\n",
        "                label = result[\"label\"]\n",
        "                predicted_label = label_map.get(label, \"negative\") # Default to negative if label is unexpected\n",
        "                predictions.append(predicted_label)\n",
        "                scores.append(result[\"score\"])\n",
        "\n",
        "        df['predicted_sentiment'] = predictions\n",
        "        df['sentiment_score'] = scores\n",
        "\n",
        "        df.to_csv(output_path, index=False)\n",
        "        logger.info(f\"Predictions saved to {output_path}\")\n",
        "\n",
        "        logger.info(\"Sample predictions:\")\n",
        "        logger.info(df[['text', 'predicted_sentiment', 'sentiment_score']].head().to_string())\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error predicting sentiments: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUTMhF4ATREp"
      },
      "outputs": [],
      "source": [
        "# Main Pipeline\n",
        "def financial_insight_pipeline(texts, model_path=\"ProsusAI/finbert\"):\n",
        "    \"\"\"Complete pipeline with configurable sentiment model.\"\"\"\n",
        "    results = []\n",
        "    for text in texts:\n",
        "        sentences = preprocess_text(text)\n",
        "        entities = extract_entities(sentences)\n",
        "        relevance_results = classify_relevance(sentences)\n",
        "        relevant_sentences = [r[\"sentence\"] for r in relevance_results if r[\"is_relevant\"]]\n",
        "        if not relevant_sentences:  # Ensure at least one sentence for sentiment\n",
        "            relevant_sentences = sentences[:1] or [text[:512]]\n",
        "            logger.warning(f\"No relevant sentences for text: {text[:50]}... Using first sentence.\")\n",
        "        sentiment_results = analyze_sentiment(relevant_sentences, model_id=model_path) # Corrected argument name\n",
        "        article_summary = summarize_text(\" \".join(sentences)) if sentences else text[:50]\n",
        "        aggregated_sentiment = aggregate_sentiment(sentiment_results)\n",
        "        results.append({\n",
        "            \"original_text\": text,\n",
        "            \"preprocessed_sentences\": sentences,\n",
        "            \"entities\": entities,\n",
        "            \"relevance\": relevance_results,\n",
        "            \"sentiments\": sentiment_results,\n",
        "            \"summary\": article_summary,\n",
        "            \"aggregated_sentiment\": aggregated_sentiment\n",
        "        })\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EPhqxxvTjR0"
      },
      "outputs": [],
      "source": [
        "# Load the fine-tuned FinBERT model\n",
        "def load_fine_tuned_model(model_path=\"/content/finbert-finetuned-djia\"):\n",
        "  \"\"\"Load the fine-tuned FinBERT model for sentiment prediction.\"\"\"\n",
        "  try:\n",
        "        sentiment_pipeline = pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=model_path,\n",
        "            tokenizer=model_path,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            device=0 if torch.cuda.is_available() else -1,  # Use GPU if available\n",
        "              # Batch size for inference\n",
        "        )\n",
        "        logger.info(f\"Fine-tuned model loaded from {model_path}\")\n",
        "        return sentiment_pipeline\n",
        "  except Exception as e:\n",
        "        logger.error(f\"Error loading fine-tuned model: {e}\")\n",
        "        logger.warning(\"Falling back to pre-trained ProsusAI/finbert\")\n",
        "        return pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=\"ProsusAI/finbert\",\n",
        "            tokenizer=\"ProsusAI/finbert\",\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            device=0 if torch.cuda.is_available() else -1,\n",
        "\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKfMbtgBpzKW"
      },
      "outputs": [],
      "source": [
        "# Step 11: Evaluation Metrics\n",
        "# Evaluation\n",
        "def run_evaluation(pipeline_results, true_labels):\n",
        "    \"\"\"Evaluate sentiment classification.\"\"\"\n",
        "    try:\n",
        "        predicted_labels = [r[\"aggregated_sentiment\"][\"majority_sentiment\"] for r in pipeline_results]\n",
        "        logger.info(f\"Number of predicted labels: {len(predicted_labels)}\")\n",
        "        logger.info(f\"Number of true labels: {len(true_labels)}\")\n",
        "        logger.info(f\"Sample predicted labels: {predicted_labels[:5]}\")\n",
        "        logger.info(f\"Sample true labels: {true_labels[:5]}\")\n",
        "\n",
        "        if len(true_labels) != len(predicted_labels):\n",
        "            logger.error(f\"Mismatch in number of true and predicted labels: {len(true_labels)} vs {len(predicted_labels)}\")\n",
        "            # Truncate to minimum length to allow evaluation\n",
        "            min_length = min(len(true_labels), len(predicted_labels))\n",
        "            true_labels = true_labels[:min_length]\n",
        "            predicted_labels = predicted_labels[:min_length]\n",
        "            logger.warning(f\"Truncated to {min_length} samples for evaluation\")\n",
        "\n",
        "        metrics = evaluate_model(true_labels, predicted_labels)\n",
        "        logger.info(\"Evaluation Metrics:\")\n",
        "        logger.info(f\"Precision: {metrics['precision']:.3f}\")\n",
        "        logger.info(f\"Recall: {metrics['recall']:.3f}\")\n",
        "        logger.info(f\"F1-Score: {metrics['f1']:.3f}\")\n",
        "        logger.info(f\"Cohen's Kappa: {metrics['kappa']:.3f}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in evaluation: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kCq3sf8a1v3"
      },
      "outputs": [],
      "source": [
        "def load_real_dataset(max_rows=10):\n",
        "    \"\"\"Load Combined_News_DJIA dataset for testing.\"\"\"\n",
        "    try:\n",
        "        url = \"https://raw.githubusercontent.com/niharikabalachandra/Stock-Market-Prediction-Using-Natural-Language-Processing/master/Combined_News_DJIA.csv\"\n",
        "        df = pd.read_csv(url)\n",
        "        df['combined_news'] = df[['Top' + str(i) for i in range(1, 26)]].apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
        "        df = df.head(max_rows)\n",
        "        return df['combined_news'].tolist(), df['Label'].map({0: \"negative\", 1: \"positive\"}).tolist()\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading real dataset: {e}\")\n",
        "        return [\"Sample text for testing.\"] * max_rows, [\"negative\"] * max_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838,
          "referenced_widgets": [
            "7b7a43f986d64e54855ea2e9ab0010bb",
            "242adc691ecf4c4695d9dc27854e187d",
            "0b71b7d7f73e422cb175644d08e030e7",
            "913d60a3d5c540edb8915560ae48266d",
            "504fc3b721254566ba30465bb4dc05a0",
            "2f0e9006c85244fdb391f3967f12041f",
            "c9a65c2d17e748fdbb0489ab7fb24ac1",
            "2b8dac22e9b24ca594e6dedbd6c6d5e1",
            "64aea5f5bb1449358e6922d45abd79cf",
            "4c651cbe119447d2bf68318c8b2e3216",
            "53e2cc67093844d2838d4a7343e3346b",
            "cf8013e77578433c9c3e72d63127220d",
            "582ff23cd8064d9191216f37e2d98b6b",
            "49bdb85b4d6c4df6be931bf62124cbc9",
            "43f6004eaf6343748d33e81ab47a3af4",
            "cbcae3f15f43467799afde59289e730f",
            "c0f987e19ded4eb9934e190f3151681e",
            "92ade04ad264463c99b2da75a67d8609",
            "3cf5a28befb045fc9a65022bf7d48579",
            "92b76dc51362407ca1dbcc136544d764",
            "ed90b2d8c1e243d6a849942dd0292c3a",
            "15a4c6290a2c4c0da892ec0d8c51ab58",
            "3c5b876fc07b41c485dbef3c3fba732b",
            "66e4f2d42c014df49144228037892d4a",
            "630a5c5e96de4ea0bd9bddafd819b1b6",
            "5231c73b3157478994ef1b2d38ed274b",
            "e5ac10d221df4e57b43ec009dc50c2ef",
            "eb69375b0f614ce282aaa1ae50befb87",
            "9fe0767f61de4f5fb05c858057e36088",
            "01c631b1b7f84d2594a8b7d859c6cbdc",
            "9357e9a7a06e4524a2e07ff13bb10c88",
            "4c9459b21b73497e90466c39dd06571e",
            "177a17321b264d50a4de993ece664584"
          ]
        },
        "collapsed": true,
        "id": "GUAoK1VRXWUQ",
        "outputId": "64bf9b79-52c1-446d-994d-78688dd1728f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b7a43f986d64e54855ea2e9ab0010bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 296,450 || all params: 109,780,228 || trainable%: 0.2700\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf8013e77578433c9c3e72d63127220d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c5b876fc07b41c485dbef3c3fba732b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Error in fine-tuning: fine_tune_finbert_peft.<locals>.WeightedTrainer.compute_loss() got an unexpected keyword argument 'num_items_in_batch'\n",
            "ERROR:__main__:Error predicting sentiments: Can't find 'adapter_config.json' at 'ProsusAI/finbert'\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Exception ignored in: <function _xla_gc_callback at 0x7940c08f6480>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "WARNING:__main__:No relevant sentences for text: b'Why wont America and Nato help us? If they wont ... Using first sentence.\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-590845806.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Run full pipeline on Combined_News_DJIA for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpipeline_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinancial_insight_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfine_tuned_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1316099880.py\u001b[0m in \u001b[0;36mfinancial_insight_pipeline\u001b[0;34m(texts, model_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No relevant sentences for text: {text[:50]}... Using first sentence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msentiment_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Corrected argument name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0marticle_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0maggregated_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         results.append({\n",
            "\u001b[0;32m/tmp/ipython-input-552707842.py\u001b[0m in \u001b[0;36msummarize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutput_max_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Dynamic output length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_max_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"summary_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m               \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         if (\n\u001b[1;32m    193\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1465\u001b[0m             )\n\u001b[1;32m   1466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgeneration_mode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBEAM_SAMPLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBEAM_SEARCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m             \u001b[0;31m# 11. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2552\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3348\u001b[0m             \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_hidden_states\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3350\u001b[0;31m             \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0;31m# Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1764\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1100\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# clamp inf values to enable fp16 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mforwarded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwarded_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# convert into half-precision if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Run the Pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    logger.info(\"Running Financial Insight Extraction Pipeline with LoRA Fine-Tuning on DJIA...\")\n",
        "\n",
        "    # Fine-tune with LoRA (test with 1000 rows, set max_rows=None for full dataset)\n",
        "    fine_tuned_model_path = fine_tune_finbert_peft(max_rows=1000)\n",
        "\n",
        "    # Predict sentiments on DJIA dataset\n",
        "    predict_sentiment_djia(model_path=fine_tuned_model_path, max_rows=1000)\n",
        "\n",
        "    # Run full pipeline on Combined_News_DJIA for testing\n",
        "    texts, true_labels = load_real_dataset(max_rows=10)\n",
        "    pipeline_results = financial_insight_pipeline(texts, model_path=fine_tuned_model_path)\n",
        "\n",
        "    run_evaluation(pipeline_results, true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "fa455a8b81a745799755bc6647b53f9e",
            "ff2c710140e34b4c85ccecaa30b9b148",
            "758313eeff3c4b458d021951e5657d04",
            "2cdd9ef9170142f785c2d53bba482347",
            "4dd2ec8d64f243aab741eeca5ff5701e",
            "2f509ba15a9047a7bc0979aa0a726f92",
            "84682bd4d3834d0d868aea5673ea18b9",
            "a59e854c6564432a8a72ee840feffd23",
            "5f289257d7754d759457dbcf0d272549",
            "3e3a53186e5b45d39f672b635e8b1489",
            "3d71b3ae9d4948cd8f39c1aef7e1384b"
          ]
        },
        "id": "AXUxThslx1Pu",
        "outputId": "005ee2de-1805-4481-95ce-3c7d2fb55208"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa455a8b81a745799755bc6647b53f9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Predicting sentiments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  2.93it/s]\n"
          ]
        }
      ],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load the fine-tuned FinBERT model\n",
        "def load_fine_tuned_model(model_path=\"./finbert-finetuned-djia\"):\n",
        "    \"\"\"Load the fine-tuned FinBERT model for sentiment prediction.\"\"\"\n",
        "    try:\n",
        "        sentiment_pipeline = pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=model_path,\n",
        "            tokenizer=model_path,\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            device=0 if torch.cuda.is_available() else -1\n",
        "        )\n",
        "        logger.info(f\"Fine-tuned model loaded from {model_path}\")\n",
        "        return sentiment_pipeline\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading fine-tuned model: {e}\")\n",
        "        logger.warning(\"Falling back to pre-trained ProsusAI/finbert\")\n",
        "        return pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=\"ProsusAI/finbert\",\n",
        "            tokenizer=\"ProsusAI/finbert\",\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            device=0 if torch.cuda.is_available() else -1\n",
        "        )\n",
        "\n",
        "# Compute evaluation metrics\n",
        "def compute_metrics(true_labels, predicted_labels):\n",
        "    \"\"\"Compute precision, recall, F1-score, accuracy, and Cohen's Kappa.\"\"\"\n",
        "    try:\n",
        "        # Log unique labels for debugging\n",
        "        logger.info(f\"Unique true labels: {set(true_labels)}\")\n",
        "        logger.info(f\"Unique predicted labels: {set(predicted_labels)}\")\n",
        "\n",
        "        # Ensure labels are strings\n",
        "        true_labels = [str(label) for label in true_labels]\n",
        "        predicted_labels = [str(label) for label in predicted_labels]\n",
        "\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average=\"weighted\")\n",
        "        kappa = cohen_kappa_score(true_labels, predicted_labels)\n",
        "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "        return {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1,\n",
        "            \"kappa\": kappa,\n",
        "            \"accuracy\": accuracy\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error computing metrics: {e}\")\n",
        "        return {\n",
        "            \"precision\": 0.0,\n",
        "            \"recall\": 0.0,\n",
        "            \"f1\": 0.0,\n",
        "            \"kappa\": 0.0,\n",
        "            \"accuracy\": 0.0\n",
        "        }\n",
        "\n",
        "# Evaluate using Combined_News_DJIA test split\n",
        "def evaluate_djia(\n",
        "    file_path=None,\n",
        "    model_path=\"./finbert-finetuned-djia\",\n",
        "    test_size=0.2,\n",
        "    max_rows=None,\n",
        "    binary=True\n",
        "):\n",
        "    \"\"\"Evaluate the fine-tuned FinBERT model using a test split from Combined_News_DJIA.\"\"\"\n",
        "    try:\n",
        "        # Load the CSV\n",
        "        if file_path:\n",
        "            df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)\n",
        "        else:\n",
        "            url = \"https://raw.githubusercontent.com/niharikabalachandra/Stock-Market-Prediction-Using-Natural-Language-Processing/master/Combined_News_DJIA.csv\"\n",
        "            df = pd.read_csv(url, encoding='utf-8', low_memory=False)\n",
        "\n",
        "        logger.info(f\"DJIA CSV loaded: {df.shape}, Columns: {df.columns.tolist()}\")\n",
        "\n",
        "        # Combine Top1 to Top25 into a single text column\n",
        "        df['text'] = df[['Top' + str(i) for i in range(1, 26)]].apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
        "        df = df.dropna(subset=['text', 'Label'])\n",
        "        df['text'] = df['text'].astype(str)\n",
        "        df['true_sentiment'] = df['Label'].map({0: \"negative\", 1: \"positive\"})\n",
        "\n",
        "        # Subsample for testing (optional)\n",
        "        if max_rows is not None:\n",
        "            df = df.sample(n=min(max_rows, len(df)), random_state=42)\n",
        "            logger.info(f\"Subsampled to {len(df)} rows\")\n",
        "\n",
        "        # Create Dataset and convert true_sentiment to ClassLabel\n",
        "        dataset = Dataset.from_pandas(df[['text', 'true_sentiment']])\n",
        "        dataset = dataset.cast_column('true_sentiment', ClassLabel(names=[\"negative\", \"positive\"]))\n",
        "\n",
        "        # Split with stratification\n",
        "        dataset = dataset.train_test_split(test_size=test_size, seed=42, stratify_by_column='true_sentiment')\n",
        "        df_test = dataset['test'].to_pandas()\n",
        "\n",
        "        # Convert true_sentiment back to string to avoid numeric indices\n",
        "        df_test['true_sentiment'] = df_test['true_sentiment'].map({0: \"negative\", 1: \"positive\"})\n",
        "\n",
        "        # Predict sentiments\n",
        "        sentiment_pipeline = load_fine_tuned_model(model_path)\n",
        "        predictions = []\n",
        "        scores = []\n",
        "        if binary:\n",
        "            label_map = {\n",
        "                \"LABEL_0\": \"negative\",\n",
        "                \"LABEL_1\": \"positive\",\n",
        "                \"negative\": \"negative\",\n",
        "                \"positive\": \"positive\",\n",
        "                \"neutral\": \"negative\"  # Map neutral to negative for binary evaluation\n",
        "            }\n",
        "        else:\n",
        "            label_map = {\n",
        "                \"LABEL_0\": \"negative\",\n",
        "                \"LABEL_1\": \"neutral\",\n",
        "                \"LABEL_2\": \"positive\",\n",
        "                \"negative\": \"negative\",\n",
        "                \"neutral\": \"neutral\",\n",
        "                \"positive\": \"positive\"\n",
        "            }\n",
        "\n",
        "        # Batch processing for efficiency\n",
        "        batch_size = 16\n",
        "        texts = df_test['text'].tolist()\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting sentiments\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            batch_texts = [text[:512] for text in batch_texts]\n",
        "            results = sentiment_pipeline(batch_texts)\n",
        "            for result in results:\n",
        "                label = result[\"label\"]\n",
        "                predicted_label = label_map.get(label, \"negative\")\n",
        "                predictions.append(predicted_label)\n",
        "                scores.append(result[\"score\"])\n",
        "\n",
        "        df_test['predicted_sentiment'] = predictions\n",
        "        df_test['sentiment_score'] = scores\n",
        "\n",
        "        # Compute metrics\n",
        "        true_labels = df_test['true_sentiment'].tolist()\n",
        "        predicted_labels = df_test['predicted_sentiment'].tolist()\n",
        "        metrics = compute_metrics(true_labels, predicted_labels)\n",
        "\n",
        "        # Log metrics\n",
        "        logger.info(\"Evaluation Metrics (Combined_News_DJIA):\")\n",
        "        logger.info(f\"Precision: {metrics['precision']:.3f}\")\n",
        "        logger.info(f\"Recall: {metrics['recall']:.3f}\")\n",
        "        logger.info(f\"F1-Score: {metrics['f1']:.3f}\")\n",
        "        logger.info(f\"Cohen's Kappa: {metrics['kappa']:.3f}\")\n",
        "        logger.info(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
        "\n",
        "        # Log sample comparisons\n",
        "        logger.info(\"Sample comparisons:\")\n",
        "        logger.info(df_test[['text', 'true_sentiment', 'predicted_sentiment', 'sentiment_score']].head().to_string())\n",
        "\n",
        "        # Save results\n",
        "        df_test.to_csv(\"djia_evaluation_results.csv\", index=False)\n",
        "        logger.info(\"Results saved to djia_evaluation_results.csv\")\n",
        "\n",
        "        return metrics, df_test\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error evaluating DJIA dataset: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# Run the evaluation\n",
        "if __name__ == \"__main__\":\n",
        "    # Primary: Evaluate on Combined_News_DJIA test split\n",
        "    logger.info(\"Evaluating on Combined_News_DJIA...\")\n",
        "    metrics_djia, df_djia = evaluate_djia(max_rows=1000, binary=True)  # Limit for testing\n",
        "    if metrics_djia:\n",
        "        logger.info(\"DJIA evaluation completed successfully\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CKZYQioiRU3H",
        "outputId": "5ea3b08f-1877-4822-872e-44d6563ece51"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_djia_predicted\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"UN: Online Privacy Now Considered a Human Right Uganda president refuses to approve anti-gay Bill The Economist talks about \\\"The coming storm\\\" - 47% of today's jobs could be automated within 20 years \\\"No government is prepared for it.\\\" Suggests a radical rethinking of education and redistributive taxes towards lower-wage workers 84-year-old Canadian died in handcuffs while in U.K. immigration lockup: watchdog NSA collects millions of text messages daily in 'untargeted' global sweep Fervently Anti-Gay Uganda Among World's Top Gay Porn Consumers Behind Fervently Anti-Gay Pakistan Growing Number Of People Agree That Ed Snowden Is A Whistleblower The self-proclaimed mastermind of the September 11 attacks, Khalid Sheikh Mohammed, has released a manifesto claiming that the Quran forbids the use of violence to spread Islam Neurosurgeons from Poland transplanted nerve cells taken from the nose of man that had his spinal cord injured. He can move his legs now. (Google translate) Japan's last WWII straggler dies at 91 - Hiroo Onoda, the last Japanese imperial soldier to emerge from hiding and surrender 29 years after the end of World War II, has died. Ugandan president refuses to approve law jailing gay people for life Putin's Message to Gays in Sochi: Leave Children in Peace - Gay people should feel comfortable at the Sochi Olympics but leave children in peace, Russias President Vladimir Putin said Friday. Spain becomes first country to rely on wind as top energy source Mexican vigilante groups refuse to be disarmed by the military Activists in Wuhan block truck carrying 2,800 cats headed for Slaughter Italian MP puts on blackface in anti-immigration tirade, \\\"saying that all white Italians should do the same so as to receive benefits, free housing and preferential treatment African migrants do\\\" Buddhist Mob Group Kills Dozens of Muslims in Myanmar. Vladimir Putin: \\\"We do not have a ban on non-traditional sexual relationships. We have a ban on the propaganda of homosexuality and paedophilia. I want to underline this. Propaganda among children. These are absolutely different things  a ban on something or a ban on the propaganda of that thing.\\\" Young Greek convicted 10 months with parole for insulting religion, by facebook page with the Greek offshoot of the Flying Spaghetti Monster. A 79-year old feminist, peace activist, film-maker and member of Aosdna has been jailed for three months in Limerick Prison in relation to protests over US military use of Shannon Airport. Vomit fee proposed for Torontos taxi cabs Metals, Currency Rigging Worse Than Libor, Bafin Chief Says A blogger in Greece has been sentenced to 10 months in prison for blasphemy because he satirized a Greek Orthodox monk Jamaican Bobsled Team on verge of qualifying for Sochi Olympics, first time since 2002 Ukraine passes sweeping legislation against acts of protest\",\n          \"Govt to axe Australian Renewable Energy Agency Russia blogger bill authorized today, requires bloggers to publicize identity, all posts will be inspected by government officials and any \\\"terrorist or propagating posts\\\" are subject to fines and imprisonment. Japanese whalers have restarted operations in the north-west Pacific only weeks after the United Nation's highest court banned Japan's so-called scientific whaling program in the Antarctic Brazil Police warn visitors, 'Don't scream if robbed' Cocaine use in Britain so high it has contaminated our drinking water, report shows Over 540 million people (66.4% of electorate) just finished voting in India's month-long general election, the largest democratic exercise in the world to date The Pirate Bay to be Blocked by Australian Government IEA: Decarbonising the economy will save $71 trillion by 2050 2,000 tons of whale meat arrives in Japan from Iceland Lost Vincent van Gogh painting found in bank safe Photos of dead turtles in Chinese ship anger Filipinos Ukraine Guardsmen open fire on crowd. Nereus deep sea sub 'implodes' 10km-down David Cameron: Taxes will rise unless we can raid bank accounts 400 US mercenaries 'deployed on ground' in Ukraine military op One billion people still defecate in public despite health risks-UN France to redraw nations map to save money Ukrainian troops open artillery fire at village of Adreyevka, Donetsk region - headquarters of Donetsk region's self-defense forces Obama aims oil weapon at Putin but will he pull the trigger? Oil prices heading for major correction after Russia's attempt to use crude as a weapon to bully Western powers backfires Brazil Built The World's Second-Most Expensive Soccer Stadium In A City With No Pro Team Court orders Turkey to pay Cyprus over invasion: Europes top human rights court on Monday ordered Turkey to pay 90 million euros ($123 million) to Cyprus over the 1974 invasion of the island and its subsequent division, in one of the largest judgments in its history. Russian officials(Rogozin) attempted to smuggle lists calling on independence of Transnistria. The lists were confiscated by Moldavian officers. Mexico: A Zetas founder among 6 dead in shootout Girl who escaped Boko Haram abduction speaks publicly about ordeal Ukraine crisis: National guardsmen fire into crowd - World\",\n          \"Iraq is rushing to digitize its national library under the threat of ISIS Zimbabwe bans lion hunting after international outcry Delta bans shipment of lion, leopard, elephant, rhino, buffalo trophies Saudi ministry: 'Free expression is an abuse of religious rights' New Study from Finland: People would be happier living near a drug rehab center than living near a mosque. After having praised the friendliness of the sport, the president of a bullfighting club was gored by a bull after it jumped out of the ring and attacked him viciously. 8 Eight suitcases full of ivory seized at Zurich airport - Elephant tusks with estimated black-market value of about 265,000 were being transported from Tanzania to China via Switzerland. The tusks had been sawed into pieces to fit into the luggage. Russia makes a new claim for the Northpole Stop burning fossil fuels now: there is no CO2 'technofix', scientists warn - Researchers have demonstrated that even if a geoengineering solution to CO2 emissions could be found, it wouldnt be enough to save the oceans Airbus patents jet to fly London-New York in 1 hour Bitcoin deemed regular currency by Australian Senate Committee It is worse than Hitler, worse than AIDS, cancer or any other epidemic. It is more catastrophic than nuclear holocaust, and it must be stopped. -Creator of the list of the banned Indian porn sites Canada, a resource economy, is the only G7 country in a recession United Joins Delta Banning Big-Game Trophies After Cecil Killing Obama says no challenge greater threat to U.S. future than climate change A massive gate unearthed in Israel may have marked the entrance to a biblical city that, at its heyday, was the biggest metropolis in the region. G20 countries pay over $1,000 per citizen in fossil fuel subsidies, say IMF Worlds leading economies still paying trillions in subsidies despite pledges to phase them out, new figures show China is demanding that the Obama administration return a wealthy and politically connected businessman who fled to the United States, according to several American officials familiar with the case. Should he seek political asylum, he could become one of the most damaging defectors 7.5 year prison sentence sought for 18 Turkish journalists for reporting on alleged covert arms shipments by the Turkish government into Syria. Isis 'price list' for child slaves confirmed as genuine by UN official Zainab Bangura Women Killed Alongside Mexican Photojournalist Were Tortured &amp; Raped - 3 of the 4 women with Ruben Espinosa were assaulted before being shot in the head after an all-night party among friends in a middle-class section of Mexico City Russia calls for international cooperation to fight Islamic State Speed of glacier retreat worldwide 'historically unprecedented', says report. Researchers have recorded rapid rises in meltwater and alarming rates of glacial retreat, which are accelerating at a pace double that of a decade ago. Israeli president flooded with death threats for condemning 'Jewish terror' More than 450 civilians killed in US-led airstrikes against the Islamic State\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"__index_level_0__\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 589,\n        \"min\": 6,\n        \"max\": 1984,\n        \"num_unique_values\": 200,\n        \"samples\": [\n          1370,\n          1448\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05429044891023085,\n        \"min\": 0.502346396446228,\n        \"max\": 0.7261428236961365,\n        \"num_unique_values\": 200,\n        \"samples\": [\n          0.6500220894813538,\n          0.5817458033561707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_djia_predicted"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a31f9cc0-06d6-427a-86ed-ad72f94b592f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>true_sentiment</th>\n",
              "      <th>__index_level_0__</th>\n",
              "      <th>predicted_sentiment</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'Pirate Party Wins and Enters The European Pa...</td>\n",
              "      <td>positive</td>\n",
              "      <td>208</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.504875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iranians respond to Israeli Facebook initiativ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>909</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.614723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>German footballer Mesut Ozil donated his 300,0...</td>\n",
              "      <td>negative</td>\n",
              "      <td>1494</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.649285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Japan Prime Minister will give up his salary u...</td>\n",
              "      <td>positive</td>\n",
              "      <td>693</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.523506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mexico's Drug War: 50,000 Dead in 6 Years As a...</td>\n",
              "      <td>negative</td>\n",
              "      <td>952</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.695125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a31f9cc0-06d6-427a-86ed-ad72f94b592f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a31f9cc0-06d6-427a-86ed-ad72f94b592f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a31f9cc0-06d6-427a-86ed-ad72f94b592f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-36e270a4-72f3-4cc8-b35c-dfce8ff485dd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36e270a4-72f3-4cc8-b35c-dfce8ff485dd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-36e270a4-72f3-4cc8-b35c-dfce8ff485dd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text true_sentiment  \\\n",
              "0  b'Pirate Party Wins and Enters The European Pa...       positive   \n",
              "1  Iranians respond to Israeli Facebook initiativ...       positive   \n",
              "2  German footballer Mesut Ozil donated his 300,0...       negative   \n",
              "3  Japan Prime Minister will give up his salary u...       positive   \n",
              "4  Mexico's Drug War: 50,000 Dead in 6 Years As a...       negative   \n",
              "\n",
              "   __index_level_0__ predicted_sentiment  sentiment_score  \n",
              "0                208            positive         0.504875  \n",
              "1                909            positive         0.614723  \n",
              "2               1494            negative         0.649285  \n",
              "3                693            positive         0.523506  \n",
              "4                952            negative         0.695125  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_djia_predicted= pd.read_csv('/content/djia_evaluation_results.csv')\n",
        "df_djia_predicted.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah1arNF0UkKj"
      },
      "source": [
        "Evaluating the fine-tuned FinBERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "5af3e15944c74529a0f090110276bb6e",
            "9b625dc163b34b8eb7969798841b2549",
            "c611bd11cde64457a73ea30cff5a306f",
            "065399008b5f4d669276f9caa42b0e64",
            "8fd431206ad44203b99904764084658b",
            "985b310769fb45ad8b3982fef26cdea6",
            "89c68381f4a64eb488c18c6bcc6cd9fb",
            "848e367166bd4a9a99977dbda28e0be1",
            "04d36637b7c842b08b7f0087763e062f",
            "cc0628efbb87479db574a055de721459",
            "094d2a42a796430aa932b4506313b6b1"
          ]
        },
        "id": "HpDi34_WR3UY",
        "outputId": "a6e6e700-bd61-4550-aaf3-8789c78d9463"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5af3e15944c74529a0f090110276bb6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Predicting sentiments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:07<00:00,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combined_News_DJIA Metrics:\n",
            "Precision: 0.605\n",
            "Recall: 0.600\n",
            "F1-Score: 0.601\n",
            "Cohen's Kappa: 0.199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Primary: Evaluate on Combined_News_DJIA test split\n",
        "    logger.info(\"Evaluating on Combined_News_DJIA...\")\n",
        "    metrics_djia, df_djia = evaluate_djia(max_rows=1000, binary=True)  # Limit for testing\n",
        "    if metrics_djia:\n",
        "        logger.info(\"DJIA evaluation completed successfully\")\n",
        "        print(\"\\nCombined_News_DJIA Metrics:\")\n",
        "        print(f\"Precision: {metrics_djia['precision']:.3f}\")\n",
        "        print(f\"Recall: {metrics_djia['recall']:.3f}\")\n",
        "        print(f\"F1-Score: {metrics_djia['f1']:.3f}\")\n",
        "        print(f\"Cohen's Kappa: {metrics_djia['kappa']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD3QuthoUXN-"
      },
      "source": [
        "Testing the Fine-tuned FinBERT model on FinSen_US_Categorized_Timestamp.csv dataset to predict the sentiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNIgP1khT15f"
      },
      "outputs": [],
      "source": [
        "# Predict sentiments on the FinSen dataset\n",
        "from tqdm import tqdm\n",
        "def predict_sentiment_finsen(\n",
        "    file_path=\"/content/FinSen_US_Categorized_Timestamp.csv\",\n",
        "    model_path=\"/content/finbert-finetuned-djia\",\n",
        "    output_path=\"/content/FinSen_US_Predicted_Sentiments.csv\",\n",
        "    batch_size=16,\n",
        "    max_rows=None):\n",
        "    \"\"\"Predict sentiment for FinSen dataset using the fine-tuned FinBERT model.\"\"\"\n",
        "    try:\n",
        "        # Load the CSV\n",
        "        df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)\n",
        "        logger.info(f\"CSV loaded: {df.shape}, Columns: {df.columns.tolist()}\")\n",
        "\n",
        "        # Verify required column\n",
        "        if 'Content' not in df.columns:\n",
        "            raise ValueError(f\"Expected 'Content' column, found {df.columns.tolist()}\")\n",
        "\n",
        "        df = df.dropna(subset=['Content'])\n",
        "        df['text'] = df['Content'].astype(str)\n",
        "\n",
        "        # Subsample for testing (optional)\n",
        "        if max_rows is not None:\n",
        "            df = df.sample(n=min(max_rows, len(df)), random_state=42)\n",
        "            logger.info(f\"Subsampled to {len(df)} rows\")\n",
        "\n",
        "        # Load the model\n",
        "        sentiment_pipeline = load_fine_tuned_model(model_path)\n",
        "\n",
        "        # Predict sentiments in batches\n",
        "        predictions = []\n",
        "        scores = []\n",
        "        label_map = {\n",
        "            \"LABEL_0\": \"negative\",\n",
        "            \"LABEL_1\": \"neutral\",\n",
        "            \"LABEL_2\": \"positive\",\n",
        "            \"negative\": \"negative\",\n",
        "            \"neutral\": \"neutral\",\n",
        "            \"positive\": \"positive\"\n",
        "        }\n",
        "\n",
        "        # Process texts in batches with progress bar\n",
        "        texts = df['text'].tolist()\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting sentiments\"):\n",
        "            batch_texts = texts[i:i + batch_size]\n",
        "            batch_texts = [text[:512] for text in batch_texts]  # Pre-truncate\n",
        "            results = sentiment_pipeline(batch_texts)\n",
        "\n",
        "            for result in results:\n",
        "                label = result[\"label\"]\n",
        "                predicted_label = label_map.get(label, \"unknown\")\n",
        "                predictions.append(predicted_label)\n",
        "                scores.append(result[\"score\"])\n",
        "\n",
        "        df['predicted_sentiment'] = predictions\n",
        "        df['sentiment_score'] = scores\n",
        "\n",
        "        # Save the updated CSV\n",
        "        df.to_csv(output_path, index=False)\n",
        "        logger.info(f\"Predictions saved to {output_path}\")\n",
        "\n",
        "        # Log sample predictions\n",
        "        logger.info(\"Sample predictions:\")\n",
        "        logger.info(df[['Content', 'predicted_sentiment', 'sentiment_score']].head().to_string())\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error predicting sentiments: {e}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geGmBp_OZfhI",
        "outputId": "ce0260c3-01c7-4800-81fd-c0a930c38772"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Predicting sentiments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 971/971 [04:20<00:00,  3.73it/s]\n"
          ]
        }
      ],
      "source": [
        "# Run the prediction\n",
        "if __name__ == \"__main__\":\n",
        "    predict_sentiment_finsen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N_OwlYaW_vXJ",
        "outputId": "f42adfbb-24ca-4ebb-d7cd-e980ff1a5048"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_predicted\",\n  \"rows\": 15534,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12980,\n        \"samples\": [\n          \"US Crude Stocks Unexpectedly Rise for 2nd Week\",\n          \"US Service Sector Activity Expands the Most Since 2015\",\n          \"US Dollar Steady After Recent Weakness\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 144,\n        \"samples\": [\n          \"Producer Price Inflation MoM\",\n          \"Imports\",\n          \"Total Vehicle Sales\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2971,\n        \"samples\": [\n          \"2/05/2013\",\n          \"16/11/2018\",\n          \"1/04/2013\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15523,\n        \"samples\": [\n          \"DXY Erases GainsUnited States\\u00a0CurrencyThe dollar index fell more than 0.5% to below 105 from an 20-year high of 105.8 hit earlier in the session as risk sentiment returned to markets after it became clear that the Fed is fully committed to fighting the surging inflation. The Federal Reserve hiked the fed funds rate by 75bps, the most since 1994 while Chair Powell signaled a similar move could come at the next meeting but he does not expect 75bps moves to be common. The sharp increase in rates comes after last week the CPI report showed inflation surged unexpectedly to a 41-year high of 8.6% in May. 2022-06-15T19:50:00\",\n          \"US Unemployment Rate Down to 5-1/2 Year LowUnited States\\u00a0Unemployment RateIn April of 2014, the jobless rate fell from 6.7 percent to 6.3 percent, the lowest rate since September of 2008, as both unemployed reentering the labor market and new entrants into the labor force fell.2014-05-02T13:59:50.763\",\n          \"US Service Sector Growth Hits 8-1/2 Year High in JulyUnited States\\u00a0Non Manufacturing PmiISM non-manufacturing index rose to 58.7 in July from 56 in June, the highest since December 2005. The number was boosted by growth in business activity, new orders and employment.2014-08-05T15:13:57.01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15523,\n        \"samples\": [\n          \"DXY Erases GainsUnited States\\u00a0CurrencyThe dollar index fell more than 0.5% to below 105 from an 20-year high of 105.8 hit earlier in the session as risk sentiment returned to markets after it became clear that the Fed is fully committed to fighting the surging inflation. The Federal Reserve hiked the fed funds rate by 75bps, the most since 1994 while Chair Powell signaled a similar move could come at the next meeting but he does not expect 75bps moves to be common. The sharp increase in rates comes after last week the CPI report showed inflation surged unexpectedly to a 41-year high of 8.6% in May. 2022-06-15T19:50:00\",\n          \"US Unemployment Rate Down to 5-1/2 Year LowUnited States\\u00a0Unemployment RateIn April of 2014, the jobless rate fell from 6.7 percent to 6.3 percent, the lowest rate since September of 2008, as both unemployed reentering the labor market and new entrants into the labor force fell.2014-05-02T13:59:50.763\",\n          \"US Service Sector Growth Hits 8-1/2 Year High in JulyUnited States\\u00a0Non Manufacturing PmiISM non-manufacturing index rose to 58.7 in July from 56 in June, the highest since December 2005. The number was boosted by growth in business activity, new orders and employment.2014-08-05T15:13:57.01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"neutral\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.052351615664584815,\n        \"min\": 0.5000100135803223,\n        \"max\": 0.7730147838592529,\n        \"num_unique_values\": 15474,\n        \"samples\": [\n          0.5102564096450806,\n          0.5177639722824097\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_predicted"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-edc60b78-8bea-4e97-9d8e-02cd8cd4f15c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Time</th>\n",
              "      <th>Content</th>\n",
              "      <th>text</th>\n",
              "      <th>predicted_sentiment</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TSX Slightly Down, Books Weekly Gains</td>\n",
              "      <td>Stock Market</td>\n",
              "      <td>16/07/2023</td>\n",
              "      <td>TSX Slightly Down, Books Weekly GainsUnited St...</td>\n",
              "      <td>TSX Slightly Down, Books Weekly GainsUnited St...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.635753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UnitedHealth Hits 4-week High</td>\n",
              "      <td>stocks</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>UnitedHealth Hits 4-week HighUnited StatesÂ sto...</td>\n",
              "      <td>UnitedHealth Hits 4-week HighUnited StatesÂ sto...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.510482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cisco Systems Hits 4-week Low</td>\n",
              "      <td>stocks</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>Cisco Systems Hits 4-week LowUnited StatesÂ sto...</td>\n",
              "      <td>Cisco Systems Hits 4-week LowUnited StatesÂ sto...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.604527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AT&amp;T Hits All-time Low</td>\n",
              "      <td>stocks</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>AT&amp;T Hits All-time LowUnited StatesÂ stocksAT&amp;T...</td>\n",
              "      <td>AT&amp;T Hits All-time LowUnited StatesÂ stocksAT&amp;T...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.543571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Microsoft Hits 4-week High</td>\n",
              "      <td>stocks</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>Microsoft Hits 4-week HighUnited StatesÂ stocks...</td>\n",
              "      <td>Microsoft Hits 4-week HighUnited StatesÂ stocks...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.546965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>JPMorgan Hits 16-month High</td>\n",
              "      <td>stocks</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>JPMorgan Hits 16-month HighUnited StatesÂ stock...</td>\n",
              "      <td>JPMorgan Hits 16-month HighUnited StatesÂ stock...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.565644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>US Export Prices Fall More than Expected</td>\n",
              "      <td>Export Prices MoM</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>US Export Prices Fall More than ExpectedUnited...</td>\n",
              "      <td>US Export Prices Fall More than ExpectedUnited...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.578514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Citigroup earnings above expectations at 1.37 USD</td>\n",
              "      <td>Earnings</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>Citigroup earnings above expectations at 1.37 ...</td>\n",
              "      <td>Citigroup earnings above expectations at 1.37 ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.551805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>US Treasury Yields Below Recent Highs</td>\n",
              "      <td>Government Bond 10Y</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>US Treasury Yields Below Recent Highs United S...</td>\n",
              "      <td>US Treasury Yields Below Recent Highs United S...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.600578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Wells Fargo earnings above expectations at 1.2...</td>\n",
              "      <td>Earnings</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>Wells Fargo earnings above expectations at 1.2...</td>\n",
              "      <td>Wells Fargo earnings above expectations at 1.2...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.550157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>BlackRock earnings above expectations at 9.28 USD</td>\n",
              "      <td>Earnings</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>BlackRock earnings above expectations at 9.28 ...</td>\n",
              "      <td>BlackRock earnings above expectations at 9.28 ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.543621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>UnitedHealth earnings above expectations at 6....</td>\n",
              "      <td>Earnings</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>UnitedHealth earnings above expectations at 6....</td>\n",
              "      <td>UnitedHealth earnings above expectations at 6....</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.564053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Dollar Languishes on Dovish Fed Bets</td>\n",
              "      <td>Currency</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>Dollar Languishes on Dovish Fed BetsUnited Sta...</td>\n",
              "      <td>Dollar Languishes on Dovish Fed BetsUnited Sta...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.513230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Bitcoin Climbs as US Inflation Slows</td>\n",
              "      <td>Currency</td>\n",
              "      <td>15/07/2023</td>\n",
              "      <td>Bitcoin Climbs as US Inflation SlowsUnited Sta...</td>\n",
              "      <td>Bitcoin Climbs as US Inflation SlowsUnited Sta...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.570875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>US Budget Deficit Widens More than Expected in...</td>\n",
              "      <td>Government Budget Value</td>\n",
              "      <td>14/07/2023</td>\n",
              "      <td>US Budget Deficit Widens More than Expected in...</td>\n",
              "      <td>US Budget Deficit Widens More than Expected in...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.664311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Visa Hits 24-week High</td>\n",
              "      <td>stocks</td>\n",
              "      <td>14/07/2023</td>\n",
              "      <td>Visa Hits 24-week HighUnited StatesÂ stocksVisa...</td>\n",
              "      <td>Visa Hits 24-week HighUnited StatesÂ stocksVisa...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.525378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Amazon Hits 43-week High</td>\n",
              "      <td>stocks</td>\n",
              "      <td>14/07/2023</td>\n",
              "      <td>Amazon Hits 43-week HighUnited StatesÂ stocksAm...</td>\n",
              "      <td>Amazon Hits 43-week HighUnited StatesÂ stocksAm...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.575566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>10-Year Treasury Yield Falls for 4th Session</td>\n",
              "      <td>Government Bond 10Y</td>\n",
              "      <td>14/07/2023</td>\n",
              "      <td>10-Year Treasury Yield Falls for 4th SessionUn...</td>\n",
              "      <td>10-Year Treasury Yield Falls for 4th SessionUn...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.527830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>DXY Approaches 100</td>\n",
              "      <td>Currency</td>\n",
              "      <td>14/07/2023</td>\n",
              "      <td>DXY Approaches 100United StatesÂ CurrencyThe do...</td>\n",
              "      <td>DXY Approaches 100United StatesÂ CurrencyThe do...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.502655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>US Core PPI Rises Less than Expected</td>\n",
              "      <td>Core Producer Prices MoM</td>\n",
              "      <td>14/07/2023</td>\n",
              "      <td>US Core PPI Rises Less than ExpectedUnited Sta...</td>\n",
              "      <td>US Core PPI Rises Less than ExpectedUnited Sta...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.509960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edc60b78-8bea-4e97-9d8e-02cd8cd4f15c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edc60b78-8bea-4e97-9d8e-02cd8cd4f15c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edc60b78-8bea-4e97-9d8e-02cd8cd4f15c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e8354474-0c9c-44f0-8243-4a0e61d4562d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8354474-0c9c-44f0-8243-4a0e61d4562d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e8354474-0c9c-44f0-8243-4a0e61d4562d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                Title  \\\n",
              "0               TSX Slightly Down, Books Weekly Gains   \n",
              "1                       UnitedHealth Hits 4-week High   \n",
              "2                       Cisco Systems Hits 4-week Low   \n",
              "3                              AT&T Hits All-time Low   \n",
              "4                          Microsoft Hits 4-week High   \n",
              "5                         JPMorgan Hits 16-month High   \n",
              "6            US Export Prices Fall More than Expected   \n",
              "7   Citigroup earnings above expectations at 1.37 USD   \n",
              "8               US Treasury Yields Below Recent Highs   \n",
              "9   Wells Fargo earnings above expectations at 1.2...   \n",
              "10  BlackRock earnings above expectations at 9.28 USD   \n",
              "11  UnitedHealth earnings above expectations at 6....   \n",
              "12               Dollar Languishes on Dovish Fed Bets   \n",
              "13               Bitcoin Climbs as US Inflation Slows   \n",
              "14  US Budget Deficit Widens More than Expected in...   \n",
              "15                             Visa Hits 24-week High   \n",
              "16                           Amazon Hits 43-week High   \n",
              "17       10-Year Treasury Yield Falls for 4th Session   \n",
              "18                                 DXY Approaches 100   \n",
              "19               US Core PPI Rises Less than Expected   \n",
              "\n",
              "                         Tag        Time  \\\n",
              "0               Stock Market  16/07/2023   \n",
              "1                     stocks  15/07/2023   \n",
              "2                     stocks  15/07/2023   \n",
              "3                     stocks  15/07/2023   \n",
              "4                     stocks  15/07/2023   \n",
              "5                     stocks  15/07/2023   \n",
              "6          Export Prices MoM  15/07/2023   \n",
              "7                   Earnings  15/07/2023   \n",
              "8        Government Bond 10Y  15/07/2023   \n",
              "9                   Earnings  15/07/2023   \n",
              "10                  Earnings  15/07/2023   \n",
              "11                  Earnings  15/07/2023   \n",
              "12                  Currency  15/07/2023   \n",
              "13                  Currency  15/07/2023   \n",
              "14   Government Budget Value  14/07/2023   \n",
              "15                    stocks  14/07/2023   \n",
              "16                    stocks  14/07/2023   \n",
              "17       Government Bond 10Y  14/07/2023   \n",
              "18                  Currency  14/07/2023   \n",
              "19  Core Producer Prices MoM  14/07/2023   \n",
              "\n",
              "                                              Content  \\\n",
              "0   TSX Slightly Down, Books Weekly GainsUnited St...   \n",
              "1   UnitedHealth Hits 4-week HighUnited StatesÂ sto...   \n",
              "2   Cisco Systems Hits 4-week LowUnited StatesÂ sto...   \n",
              "3   AT&T Hits All-time LowUnited StatesÂ stocksAT&T...   \n",
              "4   Microsoft Hits 4-week HighUnited StatesÂ stocks...   \n",
              "5   JPMorgan Hits 16-month HighUnited StatesÂ stock...   \n",
              "6   US Export Prices Fall More than ExpectedUnited...   \n",
              "7   Citigroup earnings above expectations at 1.37 ...   \n",
              "8   US Treasury Yields Below Recent Highs United S...   \n",
              "9   Wells Fargo earnings above expectations at 1.2...   \n",
              "10  BlackRock earnings above expectations at 9.28 ...   \n",
              "11  UnitedHealth earnings above expectations at 6....   \n",
              "12  Dollar Languishes on Dovish Fed BetsUnited Sta...   \n",
              "13  Bitcoin Climbs as US Inflation SlowsUnited Sta...   \n",
              "14  US Budget Deficit Widens More than Expected in...   \n",
              "15  Visa Hits 24-week HighUnited StatesÂ stocksVisa...   \n",
              "16  Amazon Hits 43-week HighUnited StatesÂ stocksAm...   \n",
              "17  10-Year Treasury Yield Falls for 4th SessionUn...   \n",
              "18  DXY Approaches 100United StatesÂ CurrencyThe do...   \n",
              "19  US Core PPI Rises Less than ExpectedUnited Sta...   \n",
              "\n",
              "                                                 text predicted_sentiment  \\\n",
              "0   TSX Slightly Down, Books Weekly GainsUnited St...            negative   \n",
              "1   UnitedHealth Hits 4-week HighUnited StatesÂ sto...             neutral   \n",
              "2   Cisco Systems Hits 4-week LowUnited StatesÂ sto...            negative   \n",
              "3   AT&T Hits All-time LowUnited StatesÂ stocksAT&T...            negative   \n",
              "4   Microsoft Hits 4-week HighUnited StatesÂ stocks...             neutral   \n",
              "5   JPMorgan Hits 16-month HighUnited StatesÂ stock...             neutral   \n",
              "6   US Export Prices Fall More than ExpectedUnited...            negative   \n",
              "7   Citigroup earnings above expectations at 1.37 ...            negative   \n",
              "8   US Treasury Yields Below Recent Highs United S...             neutral   \n",
              "9   Wells Fargo earnings above expectations at 1.2...            negative   \n",
              "10  BlackRock earnings above expectations at 9.28 ...            negative   \n",
              "11  UnitedHealth earnings above expectations at 6....            negative   \n",
              "12  Dollar Languishes on Dovish Fed BetsUnited Sta...             neutral   \n",
              "13  Bitcoin Climbs as US Inflation SlowsUnited Sta...             neutral   \n",
              "14  US Budget Deficit Widens More than Expected in...            negative   \n",
              "15  Visa Hits 24-week HighUnited StatesÂ stocksVisa...             neutral   \n",
              "16  Amazon Hits 43-week HighUnited StatesÂ stocksAm...             neutral   \n",
              "17  10-Year Treasury Yield Falls for 4th SessionUn...            negative   \n",
              "18  DXY Approaches 100United StatesÂ CurrencyThe do...             neutral   \n",
              "19  US Core PPI Rises Less than ExpectedUnited Sta...            negative   \n",
              "\n",
              "    sentiment_score  \n",
              "0          0.635753  \n",
              "1          0.510482  \n",
              "2          0.604527  \n",
              "3          0.543571  \n",
              "4          0.546965  \n",
              "5          0.565644  \n",
              "6          0.578514  \n",
              "7          0.551805  \n",
              "8          0.600578  \n",
              "9          0.550157  \n",
              "10         0.543621  \n",
              "11         0.564053  \n",
              "12         0.513230  \n",
              "13         0.570875  \n",
              "14         0.664311  \n",
              "15         0.525378  \n",
              "16         0.575566  \n",
              "17         0.527830  \n",
              "18         0.502655  \n",
              "19         0.509960  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_predicted = pd.read_csv(\"/content/FinSen_US_Predicted_Sentiments.csv\")\n",
        "df_predicted.head(20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
